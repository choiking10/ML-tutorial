{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2016_Gatys_NeuralStyleTransfer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNU7Jld8uqx9Mgay5Nf2A/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choiking10/ML-tutorial/blob/main/2016_Gatys_NeuralStyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQggbH5ehZnn"
      },
      "source": [
        "# Image Style Transfer\r\n",
        "\r\n",
        "Code to run Neural Style Transfer from paper Image Style Transfer Using Convolutional Neural Networks.\r\n",
        "\r\n",
        "## Reference Code\r\n",
        "\r\n",
        "Official code : https://github.com/leongatys/PytorchNeuralStyleTransfer\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr5h-HhhhYzA"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "from collections import OrderedDict\r\n",
        "from PIL import Image\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms\r\n",
        "from torch import optim\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "from collections import OrderedDict\r\n",
        "from PIL import Image\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms\r\n",
        "from torch import optim\r\n",
        "\r\n",
        "\r\n",
        "class VGG(nn.Module):\r\n",
        "    def __init__(self, pool='max'):\r\n",
        "        super(VGG, self).__init__()\r\n",
        "        self.ativ = nn.ReLU\r\n",
        "        if pool == 'max':\r\n",
        "            self.pooling = nn.MaxPool2d\r\n",
        "        elif pool == \"avg\":\r\n",
        "            self.pooling = nn.AvgPool2d\r\n",
        "        else:\r\n",
        "            assert True, \"pooling layer must be selected in ['max', 'avg']\"\r\n",
        "\r\n",
        "        self.conv0 = self.create_layer([3, 64, 64])\r\n",
        "        self.conv1 = self.create_layer([64, 128, 128])\r\n",
        "        self.conv2 = self.create_layer([128, 256, 256, 256, 256])\r\n",
        "        self.conv3 = self.create_layer([256, 512, 512, 512, 512])\r\n",
        "        self.conv4 = self.create_layer([512, 512, 512, 512, 512])\r\n",
        "        self.feature_extractor = {}\r\n",
        "        self.feature = []\r\n",
        "\r\n",
        "    def forward(self, x, layers: list):\r\n",
        "        #extractor = FeatureExtractor(self, layers)\r\n",
        "        #\r\n",
        "        # x = self.conv0(x)\r\n",
        "        # x = self.conv1(x)\r\n",
        "        # x = self.conv2(x)\r\n",
        "        # x = self.conv3(x)\r\n",
        "        # x = self.conv4(x)\r\n",
        "\r\n",
        "        # extractor.clear_hook()\r\n",
        "        ret = [None for i in range(len(layers))]\r\n",
        "\r\n",
        "        for name, module in filter(lambda n:  \".\" in n[0], self.named_modules()):\r\n",
        "            x = module(x)\r\n",
        "            if name in layers:\r\n",
        "                ret[layers.index(name)] = x\r\n",
        "        return list(ret)\r\n",
        "\r\n",
        "    def create_layer(self, param):\r\n",
        "        layer = []\r\n",
        "        start = param[0]\r\n",
        "        iter = enumerate(param)\r\n",
        "        next(iter)\r\n",
        "        for i, f in iter:\r\n",
        "            layer.append((f\"c{i-1}\", nn.Conv2d(start, f, kernel_size=3, padding=1)))\r\n",
        "            layer.append((f\"r{i-1}\", nn.ReLU(inplace=True)))\r\n",
        "            start = f\r\n",
        "        layer.append((\"p\", self.pooling(kernel_size=2, stride=2)))\r\n",
        "        return nn.Sequential(OrderedDict(layer))\r\n",
        "\r\n",
        "    def load_vgg_weight(self):\r\n",
        "        import torchvision.models as models\r\n",
        "        vgg = models.vgg19(pretrained=True)\r\n",
        "        state_dict = []\r\n",
        "        for (p_name, p_param), (v_name, v_param) in zip(self.named_parameters(), vgg.named_parameters()):\r\n",
        "            state_dict.append((p_name, v_param))\r\n",
        "        self.load_state_dict(OrderedDict(state_dict))\r\n",
        "\r\n",
        "def preprocessing():\r\n",
        "  transforms.Compose([transforms.Scale(img_size),\r\n",
        "                      transforms.ToTensor(),\r\n",
        "                      transforms.Lambda(lambda x: x[torch.LongTensor([2, 1, 0])]),\r\n",
        "                      transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], #subtract imagenet mean\r\n",
        "                                          std=[1, 1, 1]),\r\n",
        "                      transforms.Lambda(lambda x: x.mul(255))\r\n",
        "                      ])\r\n",
        "\r\n",
        "\r\n",
        "def main():\r\n",
        "    vgg = VGG(\"avg\")\r\n",
        "    vgg.load_vgg_weight()\r\n",
        "    print(vgg)\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}