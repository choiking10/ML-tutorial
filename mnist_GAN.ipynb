{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyODYgy8UWdMQUke0rKzEsLw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choiking10/ML-tutorial/blob/main/mnist_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iv2tHGUK2jV"
      },
      "source": [
        "# Test Page\r\n",
        "\r\n",
        "이 페이지는 google colab과 github 연동을 테스트하기 위한 페이지 입니다.\r\n",
        "\r\n",
        "깃허브 정리는... 언젠가 하겠지 뭐... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZD6kkKtK330"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "nGp9nOefJwCF",
        "outputId": "8c672b71-2e7f-47ba-9c7c-3f63f6ae04fe"
      },
      "source": [
        "import os\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.utils import save_image\r\n",
        "from IPython.display import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def grid_image(tensor_images, size=10, nrow=5):\r\n",
        "  tensor_images = ((tensor_images + 1) / 2 ).clamp(0, 1)\r\n",
        "  return torchvision.utils.make_grid(tensor_images[:size], nrow=nrow)\r\n",
        "\r\n",
        "def show_image(tensor_images, size=10, nrow=5):\r\n",
        "  to_pil = transforms.ToPILImage()\r\n",
        "  grid_img = grid_image(tensor_images)\r\n",
        "  plt.imshow(to_pil(grid_img), interpolation=\"bicubic\")\r\n",
        "\r\n",
        "class Discriminator(nn.Module):\r\n",
        "  def __init__(self, image_size, hidden_size):\r\n",
        "    super(Discriminator, self).__init__()\r\n",
        "    self.main = nn.Sequential(\r\n",
        "        nn.Linear(image_size, hidden_size),\r\n",
        "        nn.LeakyReLU(0.2),\r\n",
        "        nn.Linear(hidden_size, hidden_size),\r\n",
        "        nn.LeakyReLU(0.2),\r\n",
        "        nn.Linear(hidden_size, 1),\r\n",
        "        nn.Sigmoid()\r\n",
        "    )\r\n",
        "  def forward(self, x):\r\n",
        "    return self.main(x)\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "  def __init__(self, latent_size, hidden_size, image_size):\r\n",
        "    super(Generator, self).__init__()\r\n",
        "    self.main = nn.Sequential(\r\n",
        "        nn.Linear(latent_size, hidden_size),\r\n",
        "        nn.ReLU(0.2),\r\n",
        "        nn.Linear(hidden_size, hidden_size),\r\n",
        "        nn.ReLU(0.2),\r\n",
        "        nn.Linear(hidden_size, image_size),\r\n",
        "        nn.Tanh()\r\n",
        "    )\r\n",
        "  def forward(self, x):\r\n",
        "    return self.main(x)\r\n",
        "\r\n",
        "def main():\r\n",
        "  \r\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "  print(f\"using device {device}\")\r\n",
        "  # Hyper-parameters\r\n",
        "\r\n",
        "  latent_size = 64\r\n",
        "  hidden_size = 256\r\n",
        "  image_size = 784\r\n",
        "\r\n",
        "  num_epochs = 200\r\n",
        "  batch_size = 300\r\n",
        "  sample_dir = 'samples'\r\n",
        "\r\n",
        "  if not os.path.exists(sample_dir):\r\n",
        "    os.makedirs(sample_dir)\r\n",
        "\r\n",
        "  transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])                              \r\n",
        "  ])\r\n",
        "\r\n",
        "  mnist = torchvision.datasets.MNIST(root='../../data/',\r\n",
        "                                    train=True,\r\n",
        "                                    transform=transform,\r\n",
        "                                    download=True)\r\n",
        "\r\n",
        "  data_loader = torch.utils.data.DataLoader(dataset=mnist,\r\n",
        "                                            batch_size=batch_size,\r\n",
        "                                            shuffle=True)\r\n",
        "\r\n",
        "  D = Discriminator(image_size, hidden_size).to(device)\r\n",
        "  G = Generator(latent_size, hidden_size, image_size).to(device)\r\n",
        "\r\n",
        "  criterion = nn.BCELoss()\r\n",
        "  d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\r\n",
        "  g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\r\n",
        "\r\n",
        "  total_step = len(data_loader)\r\n",
        "  def reset_grad():\r\n",
        "    d_optimizer.zero_grad()\r\n",
        "    g_optimizer.zero_grad()\r\n",
        "  \r\n",
        "  def rand_z():\r\n",
        "    return torch.randn(batch_size, latent_size).to(device)\r\n",
        "\r\n",
        "  for epoch in range(num_epochs):\r\n",
        "    fake_images = None\r\n",
        "    for i, (images, _) in enumerate(data_loader):\r\n",
        "      images = images.view(batch_size, -1).to(device)\r\n",
        "\r\n",
        "      real_label = torch.ones(batch_size, 1).to(device)\r\n",
        "      fake_label = torch.zeros(batch_size, 1).to(device)\r\n",
        "\r\n",
        "      # ---- D ----\r\n",
        "      z = rand_z()\r\n",
        "\r\n",
        "      # real\r\n",
        "      real_outputs = D(images)\r\n",
        "      d_loss_real = criterion(real_outputs, real_label)\r\n",
        "      real_score = real_outputs\r\n",
        "\r\n",
        "      # fake\r\n",
        "      fake_images = G(z)\r\n",
        "      fake_outputs = D(fake_images)\r\n",
        "      d_loss_fake = criterion(fake_outputs, fake_label)\r\n",
        "      fake_score = fake_outputs\r\n",
        "      \r\n",
        "      # loss\r\n",
        "      d_loss = d_loss_real + d_loss_fake\r\n",
        "      \r\n",
        "      # backprop\r\n",
        "      reset_grad()\r\n",
        "      d_loss.backward()\r\n",
        "      d_optimizer.step()\r\n",
        "\r\n",
        "      # ---- G ----\r\n",
        "      z = rand_z()\r\n",
        "      fake_images = G(z)\r\n",
        "      outputs = D(fake_images)\r\n",
        "      g_loss = criterion(outputs, real_label)\r\n",
        "      \r\n",
        "      reset_grad()\r\n",
        "      g_loss.backward()\r\n",
        "      g_optimizer.step()\r\n",
        "\r\n",
        "      if (i + 1) % 200 == 0:\r\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Step [{i+1}/{total_step}],' + \r\n",
        "        f'd_loss: {d_loss:.8f}, g_loss: {g_loss:.8f}, ' + \r\n",
        "        f'D(x): {real_score.mean():.2f}, D(G(z)): {fake_score.mean():.2f}')\r\n",
        "    if (epoch + 1) % 10 == 0:\r\n",
        "      save_image(grid_image(fake_images.view(batch_size, 1, 28, 28)),\r\n",
        "                  os.path.join(sample_dir, f'real_images_{epoch:03d}.png'))\r\n",
        "      # show_image(fake_images.view(batch_size, 1, 28, 28))\r\n",
        "      \r\n",
        "      \r\n",
        "\r\n",
        "main()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [79/200], Step [400/600],d_loss: 0.61423039, g_loss: 1.96425319, D(x): 0.80, D(G(z)): 0.23\n",
            "Epoch [79/200], Step [600/600],d_loss: 0.67728984, g_loss: 1.89632070, D(x): 0.74, D(G(z)): 0.23\n",
            "Epoch [80/200], Step [200/600],d_loss: 0.78896964, g_loss: 1.53994799, D(x): 0.78, D(G(z)): 0.32\n",
            "Epoch [80/200], Step [400/600],d_loss: 0.71771699, g_loss: 1.77206588, D(x): 0.72, D(G(z)): 0.23\n",
            "Epoch [80/200], Step [600/600],d_loss: 0.89282376, g_loss: 1.89902067, D(x): 0.73, D(G(z)): 0.33\n",
            "Epoch [81/200], Step [200/600],d_loss: 0.89679956, g_loss: 1.69003677, D(x): 0.75, D(G(z)): 0.32\n",
            "Epoch [81/200], Step [400/600],d_loss: 0.86619776, g_loss: 1.51929557, D(x): 0.68, D(G(z)): 0.26\n",
            "Epoch [81/200], Step [600/600],d_loss: 0.93006009, g_loss: 1.60771835, D(x): 0.62, D(G(z)): 0.22\n",
            "Epoch [82/200], Step [200/600],d_loss: 0.92236561, g_loss: 1.82908964, D(x): 0.69, D(G(z)): 0.29\n",
            "Epoch [82/200], Step [400/600],d_loss: 0.82173753, g_loss: 1.76325464, D(x): 0.69, D(G(z)): 0.23\n",
            "Epoch [82/200], Step [600/600],d_loss: 0.82498670, g_loss: 2.08266687, D(x): 0.69, D(G(z)): 0.22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fed7b6dbc9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-fed7b6dbc9e7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0mreset_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m       \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0;31m# ---- G ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}